---
title: "MCMC from Scratch"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Goal

Gain a better understanding of what's going on under the hood in MCMC, so you'll be better at diagnosing and fixing computational problems when they occur (and they *will* occur).

## The plan

1. Simulate some data from a polynomial with noise
2. Define a model for a Bayesian polynomial regression
3. Implement Metropolis-Hastings from scratch, like your grandparents did
- We've provided basic derivations for all the quantities you'll need to compute
- We've laid out the functions you'll need to write- each one shouldn't be more than 10 or so lines
- For each function, we've written a unit test you can run. It won't ensure your code is completely right, but it'll make sure it's at least outputting the right types of things
4. Critically evaluate your MH outputs to see if you can get a reasonable answer

```{r load-libraries, message=FALSE}
library(tidyverse)
library(praise)
theme_set(theme_minimal())
source('mcmc_R_test_functions.R')
```

## 1. Synthetic Data
Lets generate some synthetic data that follows a polynomial curve. Our true curve follows this formula:

$y = x-0.4x^2+0.05x^3$

We'll use the same formula but with some additive noise to generate noisy data:

$y_{noise} = y + \mathcal{N}(0, 0.1)$

```{r synthetic-data}
# cubic curve
coefs <- c(1, -0.4, 0.05)
xvals <- seq(0, 5, length.out = 1000)
yvals <- coefs[1]*xvals + coefs[2]*xvals^2 + coefs[3]*xvals^3

# noisy cubic curve data
set.seed(1) # to keep consistent
n <- 100
noise <- rnorm(n, 0, 0.1)
x <- runif(n, 0, 5)
y <- coefs[1]*x + coefs[2]*x**2 + coefs[3]*x**3 + noise

# plot of observed (noisy) and  true (smooth) curves
ggplot() +
  geom_point(aes(x = x, y = y), color = "orange") +
  geom_line(aes(x = xvals, y = yvals), color = "blue")
```

## 2. The model
Here's a simple model we could use (that happens to also be the one the data was generated by). Our predictions $\hat{y}$ are from a polynomial:

$\hat{y}_{i} = \theta_{1}x_{i} + \theta_{2}x_{i}^{2} + \theta_{3}x_{i}^{3}$

Where we place a normally-distributed prior over each of the $\theta$s,

$\theta_{j} \sim N(0, \sigma_{j}^{2})$

and we expect the actual values are normally distributed (with standard deviation 1) around the prediction:

$y_{i} \sim N(\hat{y}, 1)$

### 2.1 What else would we include in a "real" regression model?
I left a couple things out of this example problem for simplicity. Generally we'd have:

- a parameter for the intercept
- a parameter for the variance around the prediction, instead of assuming that it's 1

### 2.2 Hyperparameters
We'll need to specify three hyperparameters- the standard deviations of the prior for each of the three regression coefficients. These are the $\sigma_j$'s in the above notation:

```{r hyperparams}
hyperparams <- c(5, 5, 5)
```

## 3. Coding up Metropolis-Hastings

### 3.1 Refresher: what does MH do?

Markov Chain Monte Carlo (MCMC) is a stochastic process used to produce samples from an arbitrary probability distribution. Metropolis-Hasting (MH) is a specific MCMC algorithm/implementation. The goal of MH is to produce accurate samples of a parameter given a function that is proportional to its probability distribution. The most natural function we can provide that fits this criteria is the product of the likelihood and prior distributions. MH works by choosing a random value of $\theta$, then choosing whether to jump to a new random value in the vicinity of the original value based on whether the likelihood*prior is higher there (and some random chance).

Start with some value for our parameters $\theta_{0}$. Each iteration $t$,

1. Sample a **candidate value** $\theta^{'}$ near $\theta_{t}$
2. Compute $f(\theta)$ for both $\theta_{t}$ and $\theta^{'}$, where $f$ is some function $f(\theta) \propto P(\theta|y)$
3. Compute the **acceptance ratio** $\alpha = f(\theta^{'})/f(\theta_{t})$
4. Sample a random number on the unit interval, $u \sim Uniform(0,1)$
5. Decide whether to accept or reject. 

* If $u \le \alpha$: **accept**; $\theta_{t+1}=\theta^{'}$
* If $u > \alpha$: **reject**; $\theta_{t+1}=\theta_{t}$


### 3.2 The plan
We're drawing samples from a function

$P(\theta|y) \propto P(y|\theta)P(\theta)$

So for the MH accept/reject decision we need to compute $P(y|\theta)P(\theta)$ for each proposed value of our regression parameters $\theta$. Since the MH acceptance depends on a ratio,

$\displaystyle \alpha = \frac{P(y|\theta^{'})P(\theta^{'})}{P(y|\theta)P(\theta)}$

we can ignore any proportionality constants. It's also generally useful, when computing with probabilities, to use logarithms so that we don't get rounding errors for values close to zero. So what we'll actually compute (remembering that $\log[a/b] = \log[a]-\log[b]$) is

$\displaystyle \log[\alpha] = \log[P(y|\theta^{'})P(\theta^{'})] - \log[P(y|\theta)P(\theta)]$

### 3.3 Prior
The prior is a normal distribution,

$\displaystyle P(\theta) = P(\theta_{1})P(\theta_{2})P(\theta_{3}) \propto \prod_{j=1}^{3}exp\left(-\frac{1}{2} \left(\frac{\theta_{j}}{\sigma_{j}}\right)^{2} \right)$

where each $\sigma_{j}$ is the prior hyperparameter for the $j$th parameter. By making any of the hyperparameters smaller, we can encode prior knowledge that that parameter should be close to zero. Our unnormalized log probability is

$\displaystyle \log[P(\theta)] = -\sum_{j=1}^{3}\frac{1}{2} \left(\frac{\theta_{j}}{\sigma_{j}}\right)^{2}$

### 3.4 Likelihood
The likelihood is also a normal distribution (of $y$ this time). If we define $\hat{y}_{i}(\theta)$ to be the prediction for observation $i$ and parameters $\theta$, then (since we've set the variance to one)

$\displaystyle P(x|\theta) = \prod_{i=1}^{N}P(y_{i}|\theta) \propto \prod_{i}exp\left(-\frac{1}{2} (y_{i} - \hat{y}_{i}(\theta))^{2} \right)$

So the unnormallized log likelihood is

$\displaystyle \log[P(x|\theta)] = -\sum_{i=1}^{N} \frac{1}{2} (y_{i} - \hat{y}_{i}(\theta))^{2}$

### 3.5 Putting it all together

Every MH update, you'll decide to accept or reject based on whether $\log[u]$ is greater or less than $\log[\alpha]$

$\displaystyle \log[\alpha] = \log[P(y|\theta^{'})P(\theta^{'})] - \log[P(y|\theta)P(\theta)] =$

$\displaystyle \left[ -\sum_{i=1}^{N} \frac{1}{2} (y_{i} - \hat{y}_{i}(\theta^{'}))^{2} -\sum_{j=1}^{3}\frac{1}{2} \left(\frac{\theta^{'}_{j}}{\sigma_{j}}\right)^{2} \right] - \left[ -\sum_{i=1}^{N} \frac{1}{2} (y_{i} - \hat{y}_{i}(\theta))^{2} -\sum_{j=1}^{3}\frac{1}{2} \left(\frac{\theta_{j}}{\sigma_{j}}\right)^{2} \right]$

### 3.6 Your mission

* write a function `pred()` that inputs a value of $\theta$ and returns predictions $\hat{y}_{i}(\theta)$ for all $i$
* write a function `log_prob()` that inputs a value of $\theta$ and returns the unnormalized log probability. It will need to call `pred()` to compute the likelihood
* write a function `metropolis_hastings_update()` that inputs a value of $\theta$ and a jump distance, and returns three things:
* the next value of $\theta$
* the corresponding log-probability (which we'll use to tune our burn-in)
* a Boolean that's `TRUE` if this was an acceptance or `FALSE` if it was a rejection (which we'll use to tune the jump distance)

A couple things you may need:

* `rnorm(3, 0, jump_distance)` to generate a Gaussian hop for a 3D array
* `runif(1)` to generate a single random number on the unit interval

## 4. Your Turn

### 4.1 Predict Y-hat values
Write the `pred()` function that accepts a vector of $\theta$ and returns a vector of $\hat{y}$. Run the function `test_pred_correct_value()` after you are done to check that it passes. If the test passes you will receive a nice message.

```{r user-pred}
#' Predict y-hat values
#' @param theta vector of coefficients
#' @return a vector of predicted y values

# DELETE CODE FOR THE LAB
pred <- function(theta) {
  theta[1]*x + theta[2]*x^2 + theta[3]*x^3
}

test_pred_correct_value()
```

### 4.2 Predict Log Probability
Write the `log_prob()` function that accepts a vector of $\theta$ and returns the unnormalized log probability. Remember that this probability takes into account both the likelihood and prior. It will need to call `pred()` to compute the likelihood. Run the function `test_log_prob()` after you are done to check that it passes.

```{r user-log-prob}
#' Compute Log probability
#' @param theta vector of coefficients
#' @return a single numeric value

# DELETE CODE FOR THE LAB
log_prob <- function(theta) {
  # our predicted y values
  yhat <- pred(theta)
  
  # likelihood
  likelihood <- -0.5*sum((y - yhat)^2)
  
  # prior
  prior <- -0.5*sum((theta/hyperparams)^2)
  
  # combined log probability
  likelihood + prior
}

test_log_prob()
```

### 4.3 MH Update
Write the `mh_update()` function that accepts a vector of $\theta$, a jump distance, and returns the next value of $\theta$, the corresponding log-probability, and a logical `TRUE` if this was an acceptance. Run the function `test_mh_update()` after you are done to check that it passes.

```{r user-mh-update}
#' Metropolis-Hastings Step
#' @param theta vector of coefficients
#' @param jump_distance standard deviation of jump
#' @return a list of 3 values: new value of theta, new log probability, and TRUE/FALSE if accepted

# DELETE CODE FOR THE LAB
mh_update <- function(theta, jump_distance) {
  # sample a candidate value near theta
  theta_new <- rnorm(length(theta), mean = theta, sd = jump_distance)
  
  # compute log prob for theta and new theta
  lp <- log_prob(theta)
  lp_new <- log_prob(theta_new)
  
  # compute log acceptance ratio
  log_alpha <- lp_new - lp
  
  # sample a random number on the unit interval
  u <- runif(1)
  
  # decide whether to accept or reject
  # and return collection of appropriate values
  is_accept <- log(u) <= log_alpha
  if (is_accept) {
    list(th = theta_new, p = lp_new, a = is_accept)
  } else {
    list(th = theta, p = lp, a = is_accept)
  }
}

test_mh_update()
```

## 5. Wrap it up and put a bow on it
Finally, write a function to manage the boring details of actually running MCMC:

- input a starting value for $\theta$ and any sampling parameters
- run MCMC
- manage and return the parameter values at every iteration, the log probability, and acceptance ratio

Run the function `test_mh()` after you are done to check that it passes.

```{r user-mh}
#' Run Metropolis-Hastings Algorithm
#' @param n number of iterations
#' @param init initial values of theta
#' @param theta vector of coefficients
#' @param jump_distance standard deviation of jump
#' @return a list with three values: matrix history of theta per iteration, history of log probs, average acceptance

# DELETE CODE FOR THE LAB
mh <- function(n = 1E4, init = c(0, 0, 0), jump_distance = 5E-3) {
  # manage values for every iteration
  theta_history <- matrix(0, nrow = n, ncol = length(init))
  lp_history <- vector("double", n)
  accept_total <- 0L
  
  # intialize theta
  theta <- init
  
  # loop for n iterations
  for (i in seq_len(n)) {
    # run update
    mh_update_output <- mh_update(theta, jump_distance)
    theta <- mh_update_output$th
    lp <- mh_update_output$p
    is_accept <- mh_update_output$a
    
    # save results
    theta_history[i,] <- theta
    lp_history[i] <- lp
    accept_total <- accept_total + is_accept
  }
  
  # return results
  list(th = theta_history, p = lp_history, a = accept_total/n)
}

test_mh()
```

## 6. Run inference and examine results
You can use the rest of this lab to experiment with your very own bespoke MCMC sampler. Below are some steps we can take to interpret the outputs of the sampler; try running under different configurations to see how good you can get your results!

```{r mh-run}
mh_output <- mh(1E5, jump_distance = 1E-2)
thetas <- mh_output$th
probs <- mh_output$p
ar <- mh_output$a
```

### 6.1 Acceptance ratio
The **acceptance ratio** (fraction of proposals that were accepted) gives us some intuition for how to set `jump_distance`. If `ar` is close to 0, then it means we're wasting a lot of time testing impractical proposals and just reiterating the same values- so we should be taking smaller steps.

If `ar` is close to 1, it probably means we're taking steps that are too small and we're not fully exploring the parameter space.

*Gelman says to aim for around 0.23*\*

\**WEAK CONVERGENCE AND OPTIMAL SCALING OF RANDOM WALK METROPOLIS ALGORITHMS* by Roberts, Gelman and Gilks, The Annals of Applied Probability 1997, Vol. 7, No. 1, 110-120).

```{r plot-ar}
ar
```

### 6.2 Log-probability

If we don't put much thought into initialization (and we didn't), the sampler might take a while to converge- the initial samples could be far from the actual posterior distribution. The log-probability can give us some insight into how many samples we should prune:

```{r plot-lp}
iteration <- seq_along(probs)
ggplot() + geom_line(aes(x = iteration, y = probs))
```

### 6.3 Parameter values

It's always a good idea to plot the values of the different parameters "over time":

```{r plot-params}
m <- ncol(thetas)
for (j in seq_len(m)) {
  p <- ggplot() +
    geom_line(aes(x = iteration, y = thetas[,j])) + 
    labs(y = sprintf("theta %s", j))
  print(p)
}

```

### 6.3 Aside: what are we looking for?

Metropolis Hastings (if everything's working right) *asymptotically* converges to the distribution being simulated. If we're in (or close to) that asymptote, the samples should look like independent draws from a stationary distribution; if not, they'll be autocorrelated.

Let's compare a stationary distribution (IID draws from normal distribution) with an autocorrelated distribution (a Gaussian random walk):

```{r iid-vs-autocorrelated}
samples <- rnorm(1E4)
random_walk <- cumsum(samples)

# plot of stationary 
ggplot() + 
  geom_line(aes(x = seq_along(samples), y = samples)) + 
  labs(title = "this is a stationary distribution")

# plot of autocorrelated distribution
ggplot() + 
  geom_line(aes(x = seq_along(samples), y = random_walk)) + 
  labs(title = "this is not")
```

We can also look at the autocorrelation directly:

```{r correlegram-samples}
acf(samples,lag.max=5000)
acf(random_walk,lag.max=5000)

```

Back to the outputs of our MCMC sampler- how do they look?

```{r  correlegram-mh}
acf(thetas[,1],lag.max=50000)
acf(thetas[,2],lag.max=50000)
acf(thetas[,3],lag.max=50000)
```

We have some options for how to address this:

- specify a "burn-in" phase where we discard the first samples (look at the log-prob plot to see how long this phase should be)
- "thin" the samples to make them less autocorrelated by keeping only every $n$th sample
- adjust sampling parameters
- collect more samples (but please make sure you have some options handy other than "brute force")
- check for correlations between parameters; you may need a different sampling algorithm
- put more thought into how we choose our initial parameter values- in more complicated models poor initialization can completely prevent the model from converging
- most importantly: **consider adjusting your model.** Remember the....Folk theorem of statistical computing

> When you have computational problems, often there's a problem with your model (Gelman)

### 6.4 Burn-in and thinning:

```{r plot-burnin}
burnin <- 20000
thin <- 10
iters <- seq(burnin, nrow(thetas), by = thin)

for (j in 1:3) {
  p <- ggplot() + 
    geom_line(aes(x = iters, y = thetas[iters,j])) + 
    #labs(y = str_c("theta_", j))
    labs(y = bquote(theta[.(j)]))
  print(p)
}
```

Plotting a histogram of the sampled values will give a picture of the marginal posterior of each parameter:

```{r plot-histogram}
for (j in 1:3) {
  p <- ggplot() + 
    geom_histogram(aes(x = thetas[iters,j]), bins = 50) +
    labs(x = bquote(theta[.(j)]))
  print(p)
}
```

We can use a few scatter plots to visualize any correlations between the parameters:

```{r plot-scatter}
for (i in 1:3) {
  j <- (i %% 3) + 1
  p <- ggplot() + 
    geom_point(aes(x = thetas[iters, i], y = thetas[iters, j]), alpha = 0.5) +
    labs(
      title = bquote(theta[.(j)]~"vs"~theta[.(i)]),
      x = bquote(theta[.(i)]),
      y = bquote(theta[.(j)])
    )
  print(p)
}
```

Even though the **priors** for our parameters are independent, the **posteriors** are highly correlated- conditioning on our data has added an interaction between all of them. So choosing a particular value for $\theta_{1}$ changes the maximum-posterior values for $\theta_{2}$ and $\theta_{3}$.

Notice that our implementation of MH didn't take these correlations into account anywhere- when we propose a new value for the parameters, it's guessing randomly in parameter space even though an increase to $\theta_{1}$ should generally mean a decrease in $\theta_{2}$. More-sophisticated MCMC samplers (like HMC and NUTS) will sample more efficiently by factoring in these relationships.

### 6.4 Yes, but does it work?

How close we need our samples to being "truly stationary" will depend on the application- even with our current rough-around-the-edges Markov chain, we can check to see whether it's learning the basic structure of our data and faithfully representing uncertainty:

```{r plot-final}
burnin <- 20000
thin <- 500
iters <- seq(burnin, nrow(thetas), by = thin)
iters <- iters[1:min(250, length(iters))]

# for each selected iteration, find the posterior predicted value for y (for each xval)
y_posterior <- map(iters, function(i) {
  y_post <- thetas[i,1]*xvals + thetas[i,2]*xvals^2 + thetas[i,3]*xvals^3
  tibble(iteration = i, x = xvals, y_post = y_post)
})

# bind these iterations together
y_posterior <- bind_rows(y_posterior)

# base plot
p <- ggplot() +
  geom_point(aes(x = x, y = y), color = "orange") +
  geom_line(aes(x = xvals, y = yvals), group = 0, color = "blue")

# add samples 
p + geom_line(aes(x = x, y = y_post, group = factor(iteration)), 
              data = y_posterior, alpha = 0.05, color='red')
```
