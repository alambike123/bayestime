{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 02\n",
    "# Examples for lecture and lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading json files\n",
    "import json\n",
    "\n",
    "# numerical libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pystan\n",
    "\n",
    "# pandas!\n",
    "import pandas as pd\n",
    "\n",
    "# plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a nice machine-readable dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absentee Ballot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absentee_df = pd.read_csv('absentee.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absentee_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas added a column for the index in the CSV\n",
    "absentee_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# fix the year column\n",
    "absentee_df['year'] = absentee_df['year'] + 1900\n",
    "\n",
    "# make a key that uniquely identifies each row\n",
    "absentee_df['yrdt'] = [int(str(absentee_df.iloc[i,0]).replace('\\n','')+'0'+str(absentee_df.iloc[i,1])) for i in range(len(absentee_df))]\n",
    "\n",
    "# and make it the index\n",
    "absentee_df.set_index('yrdt',inplace=True)\n",
    "\n",
    "# and output the dataframe to a dictionary\n",
    "absentee_data_dict = absentee_df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the metadata for the dataset\n",
    "absentee_dict = {'info':'In November 1993, the state of Pennsylvania conducted elections for its state legislature. The result in the Senate election in the 2nd district (based in Philadelphia) was challenged in court, and ultimately overturned. The Democratic candidate won 19,127 of the votes cast by voting machine, while the Republican won 19,691 votes cast by voting machine, giving the Republican a lead of 564 votes. However, the Democrat won 1,396 absentee ballots, while the Republican won just 371 absentee ballots, more than offsetting the Republican lead based on the votes recorded by machines on election day. The Republican candidate sued, claiming that many of the absentee ballots were fraudulent. The judge in the case solicited expert analysis from Orley Ashenfelter, an economist at Princeton University. Ashenfelter examined the relationship between absentee vote margins and machine vote margins in 21 previous Pennsylvania Senate elections in seven districts in the Philadelphia area over the preceding decade.',\n",
    "                 'source':'Ashenfelter, Orley. 1994. Report on Expected Asbentee Ballots. Typescript. Department of Economics, Princeton University.',\n",
    "                 'url':'https://CRAN.R-project.org/package=pscl',\n",
    "                 'vars':{'year':'a numeric vector, year of election, 19xx',\n",
    "                         'district':'a numeric vector, Pennsylvania State Senate district',\n",
    "                         'absdem':'a numeric vector, absentee ballots cast for the Democratic candidate',\n",
    "                         'absrep':'a numeric vector, absentee ballots cast for the Republican candidate',\n",
    "                         'machdem':'a numeric vector, votes cast on voting machines for the Democratic candidate',\n",
    "                         'machrep':'a numeric vector, votes cast on voting machines for the Republican candidate',\n",
    "                         'dabs':'a numeric vector, Democratic margin among absentee ballots',\n",
    "                         'dmach':'a numeric vector, Democratic margin among ballots case on voting machines'\n",
    "                         }\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store data with metadata\n",
    "absentee_dict['data'] = absentee_data_dict\n",
    "\n",
    "# do we have all the info in the dictionary?\n",
    "absentee_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write metadata to a dictionary\n",
    "with open('absentee_data.json', 'w') as fp:\n",
    "    json.dump(absentee_dict, fp)\n",
    "\n",
    "# close the file\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math score data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_data = pd.read_csv('hsb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column\n",
    "math_data.rename(columns={'Unnamed: 0':'student_id'},inplace=True)\n",
    "\n",
    "# and make it the index\n",
    "math_data.set_index('student_id',inplace=True)\n",
    "\n",
    "# and output the dataframe to a dictionary\n",
    "math_data_dict = math_data.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_dict = {'info':'The data file used for this presentation is from the 1982 High School and Beyond Survey and is used extensively in Hierarchical Linear Models by Raudenbush and Bryk. It consists of 7,185 students nested in 160 schools. ',\n",
    "             'source':'High School & Beyond (HS&B) is a nationally representative, longitudinal study of 10th and 12th graders in 1980. Follow-up surveys conducted throughout their postsecondary years. Surveys of students, teachers, and parents of sampled students. https://nces.ed.gov/surveys/hsb/',\n",
    "             'url':' https://CRAN.R-project.org/package=merTools',\n",
    "             'vars':{'schid':'a numeric vector, 160 unique values',\n",
    "                     'mathach':'a numeric vector for the performance on a standardized math assessment',\n",
    "                     'female':'a numeric vector coded 0 for male and 1 for female',\n",
    "                     'ses':'a numeric measure of student socio-economic status',\n",
    "                     'minority':'a numeric vector coded 0 for white and 1 for non-white students',\n",
    "                     'schtype':'a numeric vector coded 0 for public and 1 for private schools',\n",
    "                     'meanses':'a numeric, the average SES for each school in the data set',\n",
    "                     'size':'a numeric for the number of students in the school'\n",
    "                    }\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store data with metadata\n",
    "math_dict['data'] = math_data_dict\n",
    "\n",
    "# do we have all the info in the dictionary?\n",
    "math_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write metadata to a dictionary\n",
    "with open('math_data.json', 'w') as fp:\n",
    "    json.dump(math_dict, fp)\n",
    "\n",
    "# close the file\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rock the Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtv_data = pd.read_csv('rock_the_vote.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column\n",
    "rtv_data.rename(columns={'Unnamed: 0':'cable_system_id'},inplace=True)\n",
    "\n",
    "# and make it the index\n",
    "rtv_data.set_index('cable_system_id',inplace=True)\n",
    "\n",
    "# and output the dataframe to a dictionary\n",
    "rtv_data_dict = math_data.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtv_dict = {'info':'Voter turnout data spanning 85 cable TV systems, randomly allocated to a voter mobilization experiment targetting 18-19 year olds with \"Rock the Vote\" television advertisments. Green and Vavreck (2008) implemented a cluster-randomized experimental design in assessing the effects of a voter mobilization treatment in the 2004 U.S. Presidential election. The clusters in this design are geographic areas served by a single cable television system. So as to facilitate analysis, the researchers restricted their attention to small cable systems whose reach is limited to a single zip code. Further, since the experiment was fielded during the last week of the presidential election, the researchers restricted their search to cable systems that were not in the 16 hotly-contested “battleground” states (as designated by the Los Angeles Times).',\n",
    "            'source':'Green, Donald P. and Lynn Vavreck. 2008. Analysis of Cluster-Randomized Experiments: A Comparison of Alternative Estimation Approaches. Political Analysis 16:138-152.',\n",
    "            'url':' https://CRAN.R-project.org/package=pscl',\n",
    "            'vars':{'strata':'numeric, experimental strata',\n",
    "                    'treated':'numeric, 1 if a treated cable system, 0 otherwise',\n",
    "                    'r':'numeric, number of 18 and 19 year olds turning out',\n",
    "                    'n':'numeric, number of 19 and 19 year olds registered',\n",
    "                    'p':'numeric, proportion of 18 and 19 year olds turning out',\n",
    "                    'treatedIndex':'numeric, a counter indexing the 42 treated units'\n",
    "                   }\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store data with metadata\n",
    "rtv_dict['data'] = rtv_data_dict\n",
    "\n",
    "# do we have all the info in the dictionary?\n",
    "rtv_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write metadata to a dictionary\n",
    "with open('rock_the_vote.json', 'w') as fp:\n",
    "    json.dump(rtv_dict, fp)\n",
    "\n",
    "# close the file\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English Premier League"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epl_data = pd.read_csv('epl_scores_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column\n",
    "epl_data.rename(columns={'Unnamed: 0':'id'},inplace=True)\n",
    "\n",
    "# and make it the index\n",
    "epl_data.set_index('id',inplace=True)\n",
    "\n",
    "# rename columns \n",
    "rename_dict = {}\n",
    "cols = list(epl_data.columns)\n",
    "\n",
    "for c in cols:\n",
    "    rename_dict[c] = c.replace('epl_data.','')\n",
    "    \n",
    "epl_data.rename(columns=rename_dict,inplace=True)\n",
    "\n",
    "# and output the dataframe to a dictionary\n",
    "epl_data_dict = epl_data.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epl_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epl_dict = {'info':'This is data from the 2015/2016 season of the English Premier League, which consists of 20 teams. Each two teams play two games with each other (home and away games). There are 38 weeks and 380 games in each season. We model the score difference (home team goals − away team goals) in each match.',\n",
    "            'source':'https://github.com/stan-dev/stancon_talks/tree/master/2017/Contributed-Talks/02_kharratzadeh',\n",
    "            'url':'footbal-data.co.uk',\n",
    "            'vars':{'home_team':'numeric index of the home team',\n",
    "                    'away_team':'numeric index of the away team',\n",
    "                    'home_goals':'goals scored by home team',\n",
    "                    'away_goals':'goals scored by away team',\n",
    "                    'score_diff':'home_goals minus away_goals',\n",
    "                    'home_week':'index of the week of the home team',\n",
    "                    'away_week':'index of the week of the away team'\n",
    "                   }\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epl_teams = pd.read_csv('epl_team_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column\n",
    "epl_teams.rename(columns={'Unnamed: 0':'id'},inplace=True)\n",
    "\n",
    "# and make it the index\n",
    "epl_teams.set_index('id',inplace=True)\n",
    "\n",
    "# rename columns \n",
    "rename_dict = {}\n",
    "cols = list(epl_teams.columns)\n",
    "\n",
    "for c in cols:\n",
    "    rename_dict[c] = c.replace('epl_data.','')\n",
    "    \n",
    "epl_teams.rename(columns=rename_dict,inplace=True)\n",
    "\n",
    "# and output the dataframe to a dictionary\n",
    "epl_teams_dict = epl_teams.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epl_teams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store data with metadata\n",
    "epl_dict['data'] = epl_data_dict\n",
    "epl_dict['teams'] = epl_teams_dict\n",
    "\n",
    "# do we have all the info in the dictionary?\n",
    "epl_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write metadata to a dictionary\n",
    "with open('epl_data.json', 'w') as fp:\n",
    "    json.dump(epl_dict, fp)\n",
    "\n",
    "# close the file\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function to print a long string nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(info,wpl=12):\n",
    "    \"\"\"\n",
    "    nicely print a long paragraph\n",
    "    \"\"\"\n",
    "    \n",
    "    long_info = info.split()\n",
    "    num_lines = round(len(long_info) / wpl)\n",
    "    \n",
    "    info_break = []\n",
    "    \n",
    "    # break up the long string into multiple lines\n",
    "    for i in range(num_lines):\n",
    "        hld = ''\n",
    "        chunk = long_info[wpl*i:wpl*(i+1)]\n",
    "        \n",
    "        # piece each line into one string\n",
    "        for i in range(len(chunk)):\n",
    "            hld = hld + chunk[i] + ' '\n",
    "        \n",
    "        info_break.append(hld)\n",
    "    \n",
    "    # now print!\n",
    "    for i in range(len(info_break)):\n",
    "        print(info_break[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vars(var_dict):\n",
    "    \"\"\"\n",
    "    nicely print the infomation about each variable\n",
    "    \"\"\"\n",
    "    # what's the longest variable name?\n",
    "    max_len = 0\n",
    "    for k in var_dict.keys():\n",
    "        if len(k) > max_len:\n",
    "            max_len = len(k)\n",
    "    \n",
    "    for k in var_dict.keys():\n",
    "        len_k = len(k)\n",
    "        print(str(k) + ' '*(max_len - len_k + 1) + ' :::  ' + var_dict[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Example 1: Absentee Ballots\n",
    "\n",
    "Background information about this example is in [this New York Times article](https://www.nytimes.com/1994/04/11/us/probability-experts-may-decide-pennsylvania-vote.html). Jackman presents this example in his _Bayesian Analysis for the Social Sciences_ in Example 2.13 on pages 87-92 and Example 2.14 on pages 95-98. The exercise provides an opportunity to talk about how to construct a random variable, priors, and likelihood. In addition, this is a real world example where a judge had to make a decision about an election outcome, so further underscores our point that we need insights from noisy data to inform our choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file into a dictionary\n",
    "with open('data/absentee_data.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# close the file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the source?\n",
    "print(json_data['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where can i get these data?\n",
    "print(json_data['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some info about the dataset\n",
    "print_info(json_data['info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what variables are in the dataset?\n",
    "print_vars(json_data['vars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just give it to me in a dataframe\n",
    "data = pd.DataFrame(json_data['data'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is our question?\n",
    "\n",
    "> In November 1993 Pennsylvania conducted elections for its state legislature. The result in the Senate election in the 2nd district (based in Philadelphia) was challenged in court, and ultimately overturned. The Democratic candidate won 19, 127 of the votes cast by voting machine, while the Republican won 19,691 votes cast by voting machine, giving the Republican a lead of 564 votes. However, the Democrat won 1,396 absentee ballots, while the Republican won just 371, more than offsetting the Republican lead based on the votes recorded by machines on election day.\n",
    "> The Republican candidate sued, claiming that many of the absentee ballots were fraudulent. The judge solicited expert analysis from Orley Ashenfelter, an economist at Princeton University, who examined the relationship between absentee vote margins and machine vote margins in 21 previous Pennsylvania Senate elections in seven districts in the Philadelphia area over the preceding decade.\n",
    "\n",
    "Suppose instead that we are providing expert analysis. Should we advise the judge to throw out the election outcome, which would initiate a costly redo of the election and precipitate criminal charges against the Democratic candidate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the row of data in question\n",
    "data.loc[['199302']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is our random variable of interest?\n",
    "\n",
    "Let $i = 1, \\ldots, 21$ index the previous decade of elections.\n",
    "\n",
    "To get us thinking:\n",
    "* We want to know how unusual it is for the Democratic candidate to win 79 percent of the absentee ballots.\n",
    "* Unusual with respect to what? Past machine shares? Past absentee shares?\n",
    "* Was it a really good year for Democrats?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's usual for machine ballots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.distplot(data['machdem'][:-1]/(data['machdem'][:-1]+data['machrep'][:-1]))\n",
    "plt.axvline(0.4927353289710959,lw=3,color='black')\n",
    "plt.text(0.51,0.50,'Disputed 1993',family='serif',size=12)\n",
    "plt.text(0.51,0.43,'Outcome',family='serif',size=12)\n",
    "plt.title('Empirical PDF of Percentage of Machine Ballots for Democrats',family='serif',size=14)\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel('Percentage of Votes won by Democrats',family='serif',size=12)\n",
    "plt.ylabel('Density',family='serif',size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's usual for absentee ballots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.distplot(data['absdem'][:-1]/(data['absdem'][:-1]+data['absrep'][:-1]),color='red')\n",
    "plt.axvline(0.7900396151669496,lw=3,color='black')\n",
    "plt.text(0.58,0.38,'Disputed 1993',family='serif',size=12)\n",
    "plt.text(0.58,0.25,'Outcome',family='serif',size=12)\n",
    "plt.title('Empirical PDF of Percentage of Absentee Ballots for Democrats',family='serif',size=14)\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel('Percentage of Votes won by Democrats',family='serif',size=12)\n",
    "plt.ylabel('Density',family='serif',size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How have percentages won by Democrats varied over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the percent won by Democrats over all elections\n",
    "data['prcnt_dem_abs'] = data['absdem']/(data['absdem']+data['absrep'])\n",
    "data['prcnt_dem_mch'] = data['machdem']/(data['machdem']+data['machrep'])\n",
    "\n",
    "# compute percentiles\n",
    "lft = data.groupby('year').quantile(0.25)[['prcnt_dem_abs','prcnt_dem_mch']].rename(columns={'prcnt_dem_abs':'abs_low','prcnt_dem_mch':'mch_low'})\n",
    "mid = data.groupby('year').quantile(0.50)[['prcnt_dem_abs','prcnt_dem_mch']].rename(columns={'prcnt_dem_abs':'abs_mid','prcnt_dem_mch':'mch_mid'})\n",
    "rght = data.groupby('year').quantile(0.75)[['prcnt_dem_abs','prcnt_dem_mch']].rename(columns={'prcnt_dem_abs':'abs_hgh','prcnt_dem_mch':'mch_hgh'})\n",
    "\n",
    "# and merge together\n",
    "m1 = pd.merge(left=lft,right=mid,left_on='year',right_on='year')\n",
    "m2 = pd.merge(left=m1,right=rght,left_on='year',right_on='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# ranges\n",
    "plt.fill_between(m2.index,m2.abs_low,m2.abs_hgh,alpha=0.2,color='indigo')\n",
    "plt.fill_between(m2.index,m2.mch_low,m2.mch_hgh,alpha=0.2,color='silver')\n",
    "\n",
    "# middle of ranges\n",
    "plt.plot(m2.abs_mid,color='indigo',lw=4,label='machine ballots')\n",
    "plt.plot(m2.mch_mid,color='silver',lw=4,label='absentee ballots')\n",
    "\n",
    "# labels\n",
    "plt.title('Percent of votes won by Democrats, 1982-1992',family='serif',size=14)\n",
    "plt.ylabel('Percentage won by Democrats',family='serif',size=12)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So the previous graph shows something interesting, let's look at a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's plot all the relationships between machine and absentee votes\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(data['machdem']/(data['machdem']+data['machrep']),data['absdem']/(data['absdem']+data['absrep']),color='plum')\n",
    "plt.text(0.50,0.80,'Disputed 1993 Outcome',family='serif',size=12)\n",
    "plt.plot(0.4927353289710959,0.7900396151669496, marker='o', markersize=8, color=\"indigo\")\n",
    "plt.title('Percentage of Machine versus Absentee Ballots won by Democrats',family='serif',size=14)\n",
    "plt.xlim(0.3,1)\n",
    "plt.ylim(0.3,1)\n",
    "plt.xlabel('Machine',family='serif',size=12)\n",
    "plt.ylabel('Absentee',family='serif',size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's translate this to a random variable\n",
    "\n",
    "Let our random variable be $y_i = a_i - m_i$. Where $a_i$ is the Democratic percentage of the two-party vote cast via absentee ballot; $m_i$ is the Democratic percentage of the two-party vote cast via machine ballot; and $y_i$ is the difference between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for $y_i$\n",
    "\n",
    "To a Bayesian a model is a likelihood and a prior.\n",
    "\n",
    "#### Likilihood\n",
    "We will use a normal likelihood for this random variable:\n",
    "$y_i \\sim \\textrm{Normal}(\\mu,\\sigma)$\n",
    "\n",
    "Why a normal likelihood? The variable is continuous and varies from $(-100,100)$. \n",
    "\n",
    "#### Priors\n",
    "We need to put priors on the two parameters of the Normal distribution, the mean, $\\mu$, and variance, $\\sigma^2$. \n",
    "\n",
    "What should we use for the prior of $\\mu$?\n",
    "* How would be expect the mean difference between absentee versus machine percentages to be? \n",
    "* It has to be between $(-100,100)$.\n",
    "* Do we expect there to be differences in the use of absentee ballots by Democrats and Republicans?\n",
    "* Are Democratic-leaning districts better at turning out absentee voters?\n",
    "\n",
    "How much do we think the difference varies over elections? ie, the variance.\n",
    "* How often will the mean be between plus or minus $\\tau$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# talk about Cromwell's rule, how does our posterior look if we completely rule out differences greater than 25?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a prior predictive check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model using Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a few graphical posterior predictive checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what should our decision be? and how would we write this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Example 2: Rock the Vote\n",
    "\n",
    "Jackman presents this example in his _Bayesian Analysis for the Social Sciences_ in Example 7.9 on pages 355-362. The exercise provides an opportunity to estimate a binomial dependent variable and sets us up to talk about this example later when we talk about multi-level models. Also, a great opportunity to dive into Bayesian modeling in the context of a field experiment.\n",
    "\n",
    ">Prior to the presidential election in November 2004, we assembled a nationwide list of cable systems that covered only a single zip code. Small cable TV systems are a fertile source of experimental data for social scientists because their small size makes them inexpensive and conducive to large-N randomized studies. In order to test the televised messages in an environment that would not be dominated by other election-related advertisements, we removed all cable systems in 16 states that the Los Angeles Times classified as presidential battlegrounds (closely contested states). We then excluded any systems that had no time available in prime time during the week before the election or that cost more than 15 dollars per 30-second advertisement on the USA television network. We excluded all systems in Mississippi because its voter file is very difficult to obtain. This left 85 cable systems for randomization.\n",
    "\n",
    ">Random assignment of the cable systems took place as follows. Each system was matched with one or two other systems in the same state according to its past turnout rate in presidential elections. This procedure resulted in 40 strata containing the 85 cable systems. After sorting the list of 85 cable systems by strata and then by a random number, the first cable system in each stratum was assigned to the treatment condition, the others to control.\n",
    "\n",
    ">People living within the treatment systems saw two different 30-second advertisements produced by Rock the Vote. Both advertisements used the same format. The first dealt with the draft and the second, with education. In the draft advertisement, a young couple dancing at a party is talking about the man’s new job. He is very excited to be working in promotions and hopes to start his own firm in 6 months. The woman interrupts him and says, ‘‘That’s if you don’t get drafted.’’ The man is puzzled. She clarifies, ‘‘Drafted, for the war?’’ He responds, ‘‘Would they do that?’’ The advertisement closes with everyone at the party looking into the camera and the words, ‘‘It’s up to you’’ on the screen. The voiceover says, ‘‘The Draft. One of the issues that will be decided this November. Remember to vote on November 2nd.’’ The closing image is of the Rock the Vote logo on a black screen.\n",
    "\n",
    ">The second Rock the Vote advertisement dealt with education. A young man arrives at work with news that he has been accepted to college. His colleagues congratulate him and one of them asks, ‘‘Books, room, board, tuition ... how can you pay for all of that?’’ The advertisement closes with everyone looking out at the camera and the words, ‘‘It’s up to you’’ written on the screen. The voiceover is similar to the one above but with education substituted for draft. We showed both advertisements equally in all cable systems.\n",
    "\n",
    ">Each cable system comprises several thousand voters, and the entire data set encompasses approximately 850,000 registered voters. Of special  interest are the 23,869 voters who are 18 and 19 years of age, for whom this election represents the first federal election in which they are eligible to vote and to whom these ads were specifically addressed. The methodological question is what is the most efficient and reliable way to analyze these data? This question was particularly compelling since our previous mass-media turnout experiments suggested the effects of treatment were likely to be small in magnitude, but not zero (Vavreck  and Green 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphical posterior checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the conclusion? how would we communicate this to people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Example 1: Math Scores\n",
    "\n",
    "Jackman presents this example in his _Bayesian Analysis for the Social Sciences_ in Example 7.6 on pages 323-328. The exercise allows the students to begin the lab with a straightforward continuous dependent variable and also sets us up to bring up this example later when we talk about multi-level models.\n",
    "\n",
    ">The 1982 High School and Beyond Survey is a nationally representative sample of US public and Catholic schools, covering 7185 students in 160 schools. The chief outcome of interest is a standardized measure of math ability, with a mean of $12.75$ and interquartile range $[7.28, 18.32]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphical posterior checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the conclusion? how would we communicate this to people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Example 2: English Premier League Scores\n",
    "\n",
    "This is an [example](https://github.com/stan-dev/stancon_talks/tree/master/2017/Contributed-Talks/02_kharratzadeh) presented at the 2017 Stan conference. While the model presented is somewhat complicated, there are lots of ways to model these data simply in order to become familiar with the process. Thought is we make this one more open-ended and just see what people come up with. One of the students is _very interested_ in English Premier League soccer, so I also thought this would help keep people engaged.\n",
    "\n",
    ">In this case study, we provide a hierarchical Bayesian model for the English Premier League in the season of 2015/2016. The league consists of 20 teams and each two teams play two games with each other (home and away games). So, in total, there are 38 weeks, and 380 games. We model the score difference (home team goals $-$ away team goals) in each match. The main parameters of the model are the teams' abilities which is assumed to vary over the course of the 38 weeks. The initial abilities are determined by performance in the previous season plus some variation. Please see the next section for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphical posterior checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the conclusion? how would we communicate this to people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
