{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 02 \\\\\\ Examples for lecture\n",
    "## Irregularities in Absentee Voting in PA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading json files\n",
    "import json\n",
    "\n",
    "# numerical libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pystan\n",
    "\n",
    "# pandas!\n",
    "import pandas as pd\n",
    "\n",
    "# plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function to print a long string nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(info,wpl=12):\n",
    "    \"\"\"\n",
    "    nicely print a long paragraph\n",
    "    \"\"\"\n",
    "    \n",
    "    long_info = info.split()\n",
    "    num_lines = round(len(long_info) / wpl)\n",
    "    \n",
    "    info_break = []\n",
    "    \n",
    "    # break up the long string into multiple lines\n",
    "    for i in range(num_lines):\n",
    "        hld = ''\n",
    "        chunk = long_info[wpl*i:wpl*(i+1)]\n",
    "        \n",
    "        # piece each line into one string\n",
    "        for i in range(len(chunk)):\n",
    "            hld = hld + chunk[i] + ' '\n",
    "        \n",
    "        info_break.append(hld)\n",
    "    \n",
    "    # now print!\n",
    "    for i in range(len(info_break)):\n",
    "        print(info_break[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_vars(var_dict):\n",
    "    \"\"\"\n",
    "    nicely print the infomation about each variable\n",
    "    \"\"\"\n",
    "    # what's the longest variable name?\n",
    "    max_len = 0\n",
    "    for k in var_dict.keys():\n",
    "        if len(k) > max_len:\n",
    "            max_len = len(k)\n",
    "    \n",
    "    for k in var_dict.keys():\n",
    "        len_k = len(k)\n",
    "        print(str(k) + ' '*(max_len - len_k + 1) + ' :::  ' + var_dict[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Example 1: Absentee Ballots\n",
    "\n",
    "Background information about this example is in [this New York Times article](https://www.nytimes.com/1994/04/11/us/probability-experts-may-decide-pennsylvania-vote.html). Jackman presents this example in his _Bayesian Analysis for the Social Sciences_ in Example 2.13 on pages 87-92 and Example 2.14 on pages 95-98. The exercise provides an opportunity to talk about how to construct a random variable, priors, and likelihood. In addition, this is a real world example where a judge had to make a decision about an election outcome, so further underscores our point that we need insights from noisy data to inform our choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file into a dictionary\n",
    "with open('data/absentee_data.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# close the file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the source?\n",
    "print(json_data['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where can i get these data?\n",
    "print(json_data['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some info about the dataset\n",
    "print_info(json_data['info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what variables are in the dataset?\n",
    "print_vars(json_data['vars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just give it to me in a dataframe\n",
    "data = pd.DataFrame(json_data['data'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is our question?\n",
    "\n",
    "> In November 1993 Pennsylvania conducted elections for its state legislature. The result in the Senate election in the 2nd district (based in Philadelphia) was challenged in court, and ultimately overturned. The Democratic candidate won 19, 127 of the votes cast by voting machine, while the Republican won 19,691 votes cast by voting machine, giving the Republican a lead of 564 votes. However, the Democrat won 1,396 absentee ballots, while the Republican won just 371, more than offsetting the Republican lead based on the votes recorded by machines on election day.\n",
    "> The Republican candidate sued, claiming that many of the absentee ballots were fraudulent. The judge solicited expert analysis from Orley Ashenfelter, an economist at Princeton University, who examined the relationship between absentee vote margins and machine vote margins in 21 previous Pennsylvania Senate elections in seven districts in the Philadelphia area over the preceding decade.\n",
    "\n",
    "Suppose instead that we are providing expert analysis. Should we advise the judge to throw out the election outcome, which would initiate a costly redo of the election and precipitate criminal charges against the Democratic candidate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the row of data in question\n",
    "data.loc[['199302']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is our random variable of interest?\n",
    "\n",
    "Let $i = 1, \\ldots, 21$ index the previous decade of elections.\n",
    "\n",
    "To get us thinking:\n",
    "* We want to know how unusual it is for the Democratic candidate to win 79 percent of the absentee ballots.\n",
    "* Unusual with respect to what? Past machine shares? Past absentee shares?\n",
    "* Was it a really good year for Democrats?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's usual for machine ballots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.distplot(data['machdem'][:-1]/(data['machdem'][:-1]+data['machrep'][:-1]))\n",
    "plt.axvline(0.4927353289710959,lw=3,color='black')\n",
    "plt.text(0.51,0.50,'Disputed 1993',family='serif',size=12)\n",
    "plt.text(0.51,0.43,'Outcome',family='serif',size=12)\n",
    "plt.title('Empirical PDF of Percentage of Machine Ballots for Democrats',family='serif',size=14)\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel('Percentage of Votes won by Democrats',family='serif',size=12)\n",
    "plt.ylabel('Density',family='serif',size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's usual for absentee ballots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.distplot(data['absdem'][:-1]/(data['absdem'][:-1]+data['absrep'][:-1]),color='red')\n",
    "plt.axvline(0.7900396151669496,lw=3,color='black')\n",
    "plt.text(0.58,0.38,'Disputed 1993',family='serif',size=12)\n",
    "plt.text(0.58,0.25,'Outcome',family='serif',size=12)\n",
    "plt.title('Empirical PDF of Percentage of Absentee Ballots for Democrats',family='serif',size=14)\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel('Percentage of Votes won by Democrats',family='serif',size=12)\n",
    "plt.ylabel('Density',family='serif',size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How have percentages won by Democrats varied over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the percent won by Democrats over all elections\n",
    "data['prcnt_dem_abs'] = 100*(data['absdem']/(data['absdem']+data['absrep']))\n",
    "data['prcnt_dem_mch'] = 100*(data['machdem']/(data['machdem']+data['machrep']))\n",
    "\n",
    "# compute percentiles\n",
    "lft = data.groupby('year').quantile(0.25)[['prcnt_dem_abs','prcnt_dem_mch']].rename(columns={'prcnt_dem_abs':'abs_low','prcnt_dem_mch':'mch_low'})\n",
    "mid = data.groupby('year').quantile(0.50)[['prcnt_dem_abs','prcnt_dem_mch']].rename(columns={'prcnt_dem_abs':'abs_mid','prcnt_dem_mch':'mch_mid'})\n",
    "rght = data.groupby('year').quantile(0.75)[['prcnt_dem_abs','prcnt_dem_mch']].rename(columns={'prcnt_dem_abs':'abs_hgh','prcnt_dem_mch':'mch_hgh'})\n",
    "\n",
    "# and merge together\n",
    "m1 = pd.merge(left=lft,right=mid,left_on='year',right_on='year')\n",
    "m2 = pd.merge(left=m1,right=rght,left_on='year',right_on='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# ranges\n",
    "plt.fill_between(m2.index,m2.mch_low,m2.mch_hgh,alpha=0.2,color='sandybrown')\n",
    "plt.fill_between(m2.index,m2.abs_low,m2.abs_hgh,alpha=0.2,color='indigo')\n",
    "\n",
    "# middle of ranges\n",
    "plt.plot(m2.mch_mid,color='sandybrown',lw=4,label='absentee ballots')\n",
    "plt.plot(m2.abs_mid,color='indigo',lw=4,label='machine ballots')\n",
    "\n",
    "# labels\n",
    "plt.title('Percent of votes won by Democrats, 1982-1992',family='serif',size=14)\n",
    "plt.ylabel('Percentage won by Democrats',family='serif',size=12)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So the previous graph shows something interesting, let's look at a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's plot all the relationships between machine and absentee votes\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(data['machdem']/(data['machdem']+data['machrep']),data['absdem']/(data['absdem']+data['absrep']),color='mediumorchid')\n",
    "plt.text(0.50,0.80,'Disputed 1993 Outcome',family='serif',size=12)\n",
    "plt.plot(0.4927353289710959,0.7900396151669496, marker='o', markersize=8, color=\"indigo\")\n",
    "plt.title('Percentage of Machine versus Absentee Ballots won by Democrats',family='serif',size=14)\n",
    "plt.xlim(0.3,1)\n",
    "plt.ylim(0.3,1)\n",
    "plt.xlabel('Machine',family='serif',size=12)\n",
    "plt.ylabel('Absentee',family='serif',size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's translate this to a random variable\n",
    "\n",
    "Let our random variable be $y_i = a_i - m_i$. Where $a_i$ is the Democratic percentage of the two-party vote cast via absentee ballot; $m_i$ is the Democratic percentage of the two-party vote cast via machine ballot; and $y_i$ is the difference between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for $y_i$\n",
    "\n",
    "To a Bayesian a model is a likelihood and a prior.\n",
    "\n",
    "#### Likilihood\n",
    "We will use a normal likelihood for this random variable:\n",
    "$y_i \\sim \\textrm{Normal}(\\mu,\\sigma)$\n",
    "\n",
    "Why a normal likelihood? The variable is continuous and varies from $(-100,100)$, so the Normal is a not wrong first choice for epistemological and ontological reasons as dicsussed previously.\n",
    "\n",
    "#### Priors\n",
    "We need to put priors on the two parameters of the Normal distribution:\n",
    "* the mean, $\\mu$, and \n",
    "* variance, $\\sigma^2$. \n",
    "\n",
    "What should we use for the prior of $\\mu$?\n",
    "* How would we expect the mean difference between absentee versus machine percentages to be? \n",
    "* It has to be between $(-100,100)$.\n",
    "* Do we expect there to be differences in the use of absentee ballots by Democrats and Republicans?\n",
    "* Are Democratic-leaning districts better at turning out absentee voters?\n",
    "\n",
    "How much do we think the difference varies over elections? ie, the variance.\n",
    "* How often will the mean be between plus or minus $\\tau$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute our random variable\n",
    "data['y'] = data['prcnt_dem_abs'] - data['prcnt_dem_mch'] \n",
    "\n",
    "# setup figure\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# draw plot\n",
    "sns.kdeplot(data.y[:-1],shade=True,color='tomato')\n",
    "sns.rugplot(data.y[:-1], color='tomato', linewidth=2);\n",
    "sns.despine()\n",
    "plt.title('PDF of our random variable',family='serif',size=14)\n",
    "plt.xlabel('Percent Absentee minus Percent Machine',family='serif',size=12)\n",
    "plt.xlim(-50,50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building our model for $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the prior for $\\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the pdf of our prior for mu\n",
    "x_mu = np.linspace(-100,100,400)\n",
    "y_mu = sp.stats.norm.pdf(x_mu, loc=0, scale=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the prior for **mu**\n",
    "\n",
    "# setup figure\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# make the figure\n",
    "plt.plot(x_mu,y_mu,lw=3,color='slategray')\n",
    "plt.fill_between(x_mu,y_mu,alpha=0.25,color='slategray')\n",
    "sns.despine()\n",
    "\n",
    "# label the figure\n",
    "plt.xlabel('prior for $\\mu$',family='serif',size=12)\n",
    "plt.ylabel('density',family='serif',size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the prior for $\\sigma$\n",
    "\n",
    "For the variance we need a distribution that generates values greater than 0. What is some intuition for formulating prior information on the degree to which a quantity varies? One way to do this is ask yourself within what range of plus or minus $\\tau$ will 50 percent of the values lie? Picking $\\tau$ is equivalent to specifying the 75th percentile of the dependent variable.\n",
    "\n",
    "Below is a function that will give you the variance of a normal distribution such that 75 percent of the mass is below $\\tau$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_given_tau(tau):\n",
    "    \"\"\"\n",
    "    give this function what you think tau is,\n",
    "    and it will tell you what the variance\n",
    "    should be so that 75 percent of the \n",
    "    values are less than tau\n",
    "    \"\"\"\n",
    "    return tau / sp.stats.norm.ppf(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose tau is +/-3\n",
    "sigma_given_tau(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose tau is +/-10\n",
    "sigma_given_tau(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a handle of what the distributoin of $y$ looks like under these assumptions, we can plot the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, compute the pdf of our random variable given our selection of tau\n",
    "x_rv = np.linspace(-100,100,400)\n",
    "y_rv_one = sp.stats.norm.pdf(x_rv, loc=0, scale=4.447806)\n",
    "y_rv_two = sp.stats.norm.pdf(x_rv, loc=0, scale=14.82602)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup figure\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# make the figure\n",
    "plt.axvline(-3,lw=2,color='silver')\n",
    "plt.axvline(3,lw=2,color='silver')\n",
    "plt.plot(x_rv,y_rv_one,lw=3,color='cornflowerblue',label='tau = 3')\n",
    "plt.fill_between(x_rv,y_rv_one,alpha=0.25,color='cornflowerblue')\n",
    "plt.xlim(-15,15)\n",
    "sns.despine()\n",
    "\n",
    "# label the figure\n",
    "plt.title('What does our data look like if 50% of observations are between $\\pm 3$?',family='serif',size=14)\n",
    "plt.xlabel('y',family='serif',size=12)\n",
    "plt.ylabel('density',family='serif',size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put our 2 tau's side by side to see what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup figure\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# make the figure\n",
    "plt.plot(x_rv,y_rv_one,lw=3,color='cornflowerblue',label='tau = 3')\n",
    "plt.fill_between(x_rv,y_rv_one,alpha=0.25,color='cornflowerblue')\n",
    "\n",
    "plt.plot(x_rv,y_rv_two,lw=3,color='seagreen',label='tau = 10')\n",
    "plt.fill_between(x_rv,y_rv_two,alpha=0.25,color='seagreen')\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "# label the figure\n",
    "plt.title('What does our data look like if 50% of observations are between $\\pm tau$?',family='serif',size=14)\n",
    "plt.xlabel('y',family='serif',size=12)\n",
    "plt.ylabel('density',family='serif',size=12)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can translate our two chosen $\\tau$'s into a gamma distribution. The gamma distribution has non-negative support, and we can pick the parameters such that the mean is between 3 and 10. Those parameters in the ``scipy.stats`` version of the gamma distribution and the corresponding PDF are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the pdf of our prior for sigma\n",
    "x_sig = np.linspace(0,30,300)\n",
    "y_sig = sp.stats.gamma.pdf(x_sig, a=3.25, loc=0, scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the prior for **sigma**\n",
    "\n",
    "# setup figure\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# make the figure\n",
    "plt.plot(x_sig,y_sig,lw=3,color='cornflowerblue')\n",
    "plt.fill_between(x_sig,y_sig,alpha=0.25,color='cornflowerblue')\n",
    "sns.despine()\n",
    "\n",
    "# label the figure\n",
    "plt.xlabel('prior for $\\sigma$',family='serif',size=12)\n",
    "plt.ylabel('density',family='serif',size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gamma prior gives us values greater than zero, has a mean of 6 and concentrates most of the weight between 3 and 10. However, it still allows our model to find high variance values if needed---it does not rule them out (Cromwell).\n",
    "\n",
    ">[Cromwell's rule](https://en.wikipedia.org/wiki/Cromwell's_rule), named by statistician Dennis Lindley, states that the use of prior probabilities of 1 (\"the event will definitely occur\") or 0 (\"the event will definitely not occur\") should be avoided, except when applied to statements that are logically true or false, such as 2+2 equaling 4 or 5.\n",
    "\n",
    ">The reference is to Oliver Cromwell, who wrote to the General Assembly of the Church of Scotland on 5 August 1650, including a phrase that has become well known and frequently quoted:\n",
    "\n",
    ">I beseech you, in the bowels of Christ, think it possible that you may be mistaken.\n",
    "\n",
    ">If the prior probability assigned to a hypothesis is 0 or 1, then, by Bayes' theorem, the posterior probability (probability of the hypothesis, given the evidence) is forced to be 0 or 1 as well; no evidence, no matter how strong, could have any influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Bayesian Two-Step: simulating data from our priors\n",
    "\n",
    "We can now do the Bayesian Two-Step by simulating values from our priors, then sampling from our likelihood to generate data. This shows us how our priors interact with the likelihood. These interactions can be complex, but the Two-Step can handle it. \n",
    "\n",
    "Questions to think about as you look at these plots:\n",
    "1. Does our model generate plausible data? \n",
    "2. Does our model completely fail by only generating outrageous data?\n",
    "3. Does our model allow for extreme states of the world?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Bayes' Two-Step in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup simulation\n",
    "n_sim = 500\n",
    "prior_data = np.zeros(shape=(n_sim,2))\n",
    "pr_pred_draws = {}\n",
    "col_names = ['prior_mu','prior_sigma']\n",
    "n_pr_data = len(data) - 1 # number of observed data points excluding the last one\n",
    "\n",
    "# generate data\n",
    "for i in range(n_sim):\n",
    "    \n",
    "    # Step One: \n",
    "    # simulate from prior distributions\n",
    "    prior_data[i,0] = sp.stats.norm.rvs(loc=0, scale=20,size=1)[0] # simulate prior mean\n",
    "    prior_data[i,1] = sp.stats.gamma.rvs(a=3.25, loc=0, scale=2,size=1)[0] # simulate prior variance\n",
    "    \n",
    "    # Step Two: \n",
    "    # for the generated prior values,\n",
    "    # sample from our likelihood\n",
    "    pr_pred_draws[i] = sp.stats.norm.rvs(loc=prior_data[i,0], scale=prior_data[i,1],size=n_pr_data)\n",
    "   \n",
    "y_prior = pd.DataFrame(prior_data,columns=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Bayes' Two-Step in Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's in this stan model anyway?\n",
    "f = open('absentee_prior.stan', 'r')\n",
    "file_contents = f.read()\n",
    "print (file_contents)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile Stan model\n",
    "pm = pystan.StanModel(file=\"absentee_prior.stan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct MCMC using Stan\n",
    "pr_draws = pm.sampling(iter=1000, chains=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give us a dictionary containing posterior draws for each parameter in the model\n",
    "pr_pd = pr_draws.extract(permuted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_pd.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Stan & Python priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the joint distribution of our priors generated by Stan\n",
    "sns.jointplot(pr_pd['mu'], pr_pd['sigma'], kind='kde', color='slategray')\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have two parameters, we can plot the joint distribution of our priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the joint distribution of our priors generated by Python\n",
    "sns.jointplot(y_prior.prior_mu, y_prior.prior_sigma, kind='kde', color='slategray')\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior predictive Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot simulated data from our prior distributions against our observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "nscttr = 101\n",
    "#colors = sns.diverging_palette(10, 220, sep=80, n=nscttr)\n",
    "colors = sns.diverging_palette(145, 280, s=85, l=25, n=nscttr)\n",
    "\n",
    "c = 0\n",
    "for i in np.random.choice(range(n_sim),nscttr,replace=False):\n",
    "    plt.scatter(pr_pred_draws[i],data.y[:-1]+sp.stats.norm.rvs(0,0.5,size=21),color=colors[c],s=10)\n",
    "    c += 1\n",
    "\n",
    "# make it pretty\n",
    "plt.axvline(0,color='silver')\n",
    "plt.axhline(0,color='silver')\n",
    "plt.xlim(-75,75)\n",
    "plt.ylim(-40,20)\n",
    "sns.despine()\n",
    "\n",
    "# label the figure\n",
    "plt.title('Prior Predictive Distribution',family='serif',size=14)\n",
    "plt.xlabel('data sampled from prior',family='serif',size=12)\n",
    "plt.ylabel('observed data',family='serif',size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph shows us what kinds of datasets our model _can_ produce. We want it to be able to produce things that look like the data as well as extreme versions of it. Follow the clump of points at $y = -21$, these are all possibilites our model could generate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior Flipbook\n",
    "\n",
    "Now we look at a flip book of possible datasets from our prior, not against the data, but as a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup figure\n",
    "plt.figure(figsize=(15,7.5))\n",
    "\n",
    "nflips = 21\n",
    "colors = sns.diverging_palette(10, 220, sep=80, n=nflips)\n",
    "\n",
    "# plot a few randomly selected datasets generated from our prior\n",
    "c = 0\n",
    "for i in np.random.choice(range(n_sim),nflips,replace=False):\n",
    "    sns.kdeplot(pr_pred_draws[i],color=colors[c],shade=True)\n",
    "    c += 1\n",
    "    \n",
    "# make it pretty\n",
    "#plt.axvline(0,color='silver')\n",
    "plt.xlim(-75,75)\n",
    "sns.despine()\n",
    "\n",
    "# label the figure\n",
    "plt.title('Flipbook of data generated from prior',family='serif',size=14)\n",
    "plt.xlabel('y',family='serif',size=12)\n",
    "plt.ylabel('density',family='serif',size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating our model\n",
    "\n",
    "We will finally (!) estimate this model using MCMC and Stan. First we inspect our model, then we compile and conduct sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's in this stan model anyway?\n",
    "f = open('absentee.stan', 'r')\n",
    "file_contents = f.read()\n",
    "print (file_contents)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile Stan model\n",
    "sm = pystan.StanModel(file=\"absentee.stan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataset for Stan\n",
    "stan_data = {'N':len(data)-1,'y':data.y[:-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct MCMC using Stan\n",
    "fit = sm.sampling(data=stan_data, iter=4000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some pretty summary stats about the posterior\n",
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give us a dictionary containing posterior draws for each parameter in the model\n",
    "ps = fit.extract(permuted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the figure and a subplot axes.\n",
    "num_rows = 4\n",
    "num_cols = 2\n",
    "fig, ax = plt.subplots(num_rows, num_cols, figsize=(16, 16))\n",
    "\n",
    "# overall title\n",
    "fig.suptitle('Graphical depictions of the posterior',y=1.025,fontsize=18,fontfamily='serif')\n",
    "\n",
    "# ___ROW ONE___\n",
    "# **trace plots**\n",
    "ax[0,0].plot(ps['mu'],lw=1,alpha=0.75,color='cornflowerblue')\n",
    "ax[0,0].set_title('Trace plot of $\\mu$',fontsize=12,fontfamily='serif')\n",
    "ax[0,1].plot(ps['sigma'],lw=1,alpha=0.75,color='cornflowerblue')\n",
    "ax[0,1].set_title('Trace plot of $\\sigma$',fontsize=12,fontfamily='serif')\n",
    "\n",
    "# ___ROW TWO___\n",
    "# **joint distribution** of parameters\n",
    "sns.kdeplot(y_prior.prior_mu, y_prior.prior_sigma,\n",
    "            color='cornflowerblue', shade=True, shade_lowest=False,ax=ax[1,0])\n",
    "sns.kdeplot(ps['mu'], ps['sigma'],\n",
    "            color=\"salmon\", shade=True, shade_lowest=False,ax=ax[1,1])\n",
    "\n",
    "ax[1,0].set_title('Prior joint distribution of parameters',fontsize=12,fontfamily='serif')\n",
    "ax[1,0].set_xlim(-30,30)\n",
    "ax[1,0].set_ylim(0,20)\n",
    "ax[1,1].set_title('Posterior joint distribution of parameters',fontsize=12,fontfamily='serif')\n",
    "ax[1,1].set_xlim(-30,30)\n",
    "ax[1,1].set_ylim(0,20)\n",
    "\n",
    "# ___ROW THREE___\n",
    "# prior and posterior of **mu**\n",
    "ax[2,0].plot(x_mu,y_mu,lw=3,color='cornflowerblue')\n",
    "ax[2,0].fill_between(x_mu,y_mu,alpha=0.25,color='cornflowerblue')\n",
    "\n",
    "sns.kdeplot(ps['mu'],shade=True, lw=3,color='salmon',shade_lowest=False,ax=ax[2,1])\n",
    "\n",
    "ax[2,0].set_title('Prior distribution of $\\mu$',fontsize=12,fontfamily='serif')\n",
    "ax[2,0].set_xlim(-50,50)\n",
    "ax[2,1].set_title('Posterior distribution of $\\mu$',fontsize=12,fontfamily='serif')\n",
    "ax[2,1].set_xlim(-50,50)\n",
    "\n",
    "# ___ROW FOUR___\n",
    "# prior and posterior of **sigma**\n",
    "ax[3,0].plot(x_sig,y_sig,lw=3,color='cornflowerblue')\n",
    "ax[3,0].fill_between(x_sig,y_sig,alpha=0.25,color='cornflowerblue')\n",
    "\n",
    "sns.kdeplot(ps['sigma'],shade=True, lw=3,color='salmon',shade_lowest=False,ax=ax[3,1])\n",
    "\n",
    "ax[3,0].set_title('Prior distribution of $\\sigma$',fontsize=12,fontfamily='serif')\n",
    "ax[3,0].set_xlim(0,20)\n",
    "ax[3,1].set_title('Posterior distribution of $\\sigma$',fontsize=12,fontfamily='serif')\n",
    "ax[3,1].set_xlim(0,20)\n",
    "\n",
    "\n",
    "# make the plot prettier\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "nscttr = 101\n",
    "#colors = sns.diverging_palette(10, 220, sep=80, n=nscttr)\n",
    "colors = sns.diverging_palette(145, 280, s=85, l=25, n=nscttr)\n",
    "\n",
    "c = 0\n",
    "for i in np.random.choice(range(n_sim),nscttr,replace=False):\n",
    "    # randomly sample 21 values from the posterior\n",
    "    y_post = np.random.choice(ps['y_sim'],len(data.y[:-1]),replace=False)\n",
    "    \n",
    "    # then plot against observations\n",
    "    plt.scatter(y_post,data.y[:-1]+sp.stats.norm.rvs(0,0.5,size=21),color=colors[c],s=10)\n",
    "    c += 1\n",
    "\n",
    "# make it pretty\n",
    "plt.axvline(0,color='silver')\n",
    "plt.axhline(0,color='silver')\n",
    "plt.xlim(-30,20)\n",
    "plt.ylim(-30,20)\n",
    "sns.despine()\n",
    "\n",
    "# label the figure\n",
    "plt.title('Posterior Predictive Distribution',family='serif',size=14)\n",
    "plt.xlabel('data sampled from posterior',family='serif',size=12)\n",
    "plt.ylabel('observed data',family='serif',size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graphical check isn't that relevant here, because our model isn't designed to predict specific points. The main focus of the model is to uncover the distribution of the random variable of interest. To get at that, let's look at the empirical CDF of the data versus the posterior.\n",
    "\n",
    "Here is a function to compute the empirical CDF of any data series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    \"\"\" Compute ECDF \"\"\"\n",
    "    x = np.sort(data)\n",
    "    n = x.size\n",
    "    y = np.arange(1, n+1) / n\n",
    "    return(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the empirical CDF of the data and posterior\n",
    "x_data, y_data = ecdf(data.y[:-1])\n",
    "x_post, y_post = ecdf(ps['y_sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(x_data,y_data,lw=2,color='cornflowerblue',label='data')\n",
    "plt.plot(x_post,y_post,lw=2,color='salmon',label='posterior')\n",
    "\n",
    "# make it pretty\n",
    "plt.axvline(0,color='silver')\n",
    "plt.xlim(-30,20)\n",
    "sns.despine()\n",
    "\n",
    "# label the figure\n",
    "plt.title('Empirical CDF: Posterior versus Data',family='serif',size=14)\n",
    "plt.xlabel('$y$',family='serif',size=12)\n",
    "plt.ylabel('probability',family='serif',size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly more interesting way to do this, is to randomly sample 21 data points from the posterior without replacement and plot many CDFs to get a sense for how much variability is in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# plot a bunch of ECDFs from the posterior\n",
    "for i in range(300):\n",
    "    # randomly sample 21 values from the posterior\n",
    "    y_post_samp = np.random.choice(ps['y_sim'],len(data.y[:-1]),replace=False)\n",
    "    \n",
    "    # compute ECDF\n",
    "    x_post, y_post = ecdf(y_post_samp)\n",
    "    \n",
    "    # then plot \n",
    "    plt.plot(x_post,y_post,lw=0.25,alpha=0.25,color='salmon',label='posterior')\n",
    "\n",
    "# plot the CDF of the data\n",
    "plt.plot(x_data,y_data,lw=4,color='cornflowerblue',label='data')\n",
    "    \n",
    "# make it pretty\n",
    "plt.xlim(-30,20)\n",
    "plt.ylim(0,1)\n",
    "sns.despine()\n",
    "\n",
    "# label the figure\n",
    "plt.title('Empirical CDF: Posterior versus Data',family='serif',size=14)\n",
    "plt.xlabel('$y$',family='serif',size=12)\n",
    "plt.ylabel('probability',family='serif',size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does a decent job of capturing the variability of the observed posterior. There are notable departures between the posterior and data from $y = -5$ to $y = 4$, which corresponds to a region where we have few observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's answer the question\n",
    "\n",
    "How unusual it is for the Democratic candidate to win 29 percent more absentee ballots than machine ballots? \n",
    "\n",
    "We can compute this from our posterior. What is the probability that we observe $y \\geq 29.7$?\n",
    "\n",
    "$P(y \\geq 29.7 | \\mathbf{y})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this isn't observed in our posterior, so Pr(y >= 29.7) = 0 !\n",
    "y_post = pd.DataFrame(ps['y_sim'],columns=['y_sim'])\n",
    "y_post[y_post.y_sim >= 29.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a rare event, we can compute the probability directly from our posterior samples using the CDF of the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_1993 = np.zeros(len(ps['y_sim']))\n",
    "\n",
    "for i in range(len(ps['y_sim'])):\n",
    "    prob_1993[i] = 1 - sp.stats.norm.cdf(29.7,loc=ps['mu'][i],scale=ps['sigma'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.kdeplot(prob_1993,shade=True)\n",
    "sns.despine()\n",
    "\n",
    "# label the figure\n",
    "plt.title('PDF of the Computed Probablity of $y \\geq 29.7$',family='serif',size=14)\n",
    "plt.xlabel('$y$',family='serif',size=12)\n",
    "plt.ylabel('probability',family='serif',size=12)\n",
    "plt.xlim(0,0.002);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what do we tell the judge about the plausibility of observing a 29.7 difference between the percentage of absentee ballots won by Democrats and the percentage of machine ballots won by the Democrats?\n",
    "\n",
    "How would we write this up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
